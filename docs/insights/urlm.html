<!DOCTYPE html>
<html><head>
<meta charset="utf-8"/>
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<link crossorigin="" href="https://fonts.gstatic.com/" rel="preconnect"/>
<link as="style" href="https://fonts.googleapis.com/css2?display=swap&amp;family=Inter%3Awght%40400%3B500%3B600%3B700%3B900&amp;family=Noto+Sans%3Awght%40400%3B500%3B700%3B900" onload="this.rel='stylesheet'" rel="stylesheet"/>
<title>Understanding Reasoning in Language Models - David Akinboro</title>
<link href="data:image/x-icon;base64," rel="icon" type="image/x-icon"/>
<script src="https://cdn.tailwindcss.com?plugins=forms,container-queries"></script>
<style>
.hover-glow {
  transition: box-shadow 0.3s ease-in-out;
}
.hover-glow:hover {
  box-shadow: 0 0 15px 5px rgba(22, 114, 206, 0.3);
}
.active-nav-link {
  color: #1672ce;
  position: relative;
}
.active-nav-link::after {
  content: '';
  position: absolute;
  bottom: -4px;
  left: 0;
  width: 100%;
  height: 2px;
  background-color: #1672ce;
}

/* Mobile Responsive */
@media (max-width: 768px) {
  .main-container {
    padding-left: 1rem !important;
    padding-right: 1rem !important;
  }
  
  .sidebar {
    display: none;
  }
  
  .content-area {
    max-width: 100% !important;
  }
}

@media (max-width: 640px) {
  .header {
    padding-left: 1rem;
    padding-right: 1rem;
  }
  
  .nav-links {
    display: none;
  }
  
  .mobile-menu {
    display: block;
  }
}

.mobile-menu {
  display: none;
}

/* Content styling */
.content-area {
  max-width: 42rem;
  margin: 0 auto;
  padding: 2rem 1rem;
}

.content-area h1 {
  font-size: 2.5rem;
  font-weight: 700;
  color: #1e293b;
  margin-bottom: 1rem;
  line-height: 1.2;
}

.content-area h2 {
  font-size: 1.75rem;
  font-weight: 600;
  color: #1e293b;
  margin-top: 2.5rem;
  margin-bottom: 1rem;
  line-height: 1.3;
}

.content-area h3 {
  font-size: 1.25rem;
  font-weight: 600;
  color: #1e293b;
  margin-top: 2rem;
  margin-bottom: 0.75rem;
}

.content-area p {
  color: #475569;
  line-height: 1.7;
  margin-bottom: 1.25rem;
  font-size: 1rem;
}

.content-area ul {
  color: #475569;
  line-height: 1.7;
  margin-bottom: 1.25rem;
  padding-left: 1.5rem;
}

.content-area li {
  margin-bottom: 0.5rem;
}

.content-area strong {
  color: #1e293b;
  font-weight: 600;
}

.content-area em {
  font-style: italic;
}

.sidebar {
  width: 16rem;
  padding: 2rem 1rem;
  position: sticky;
  top: 6rem;
  height: fit-content;
}

.sidebar h3 {
  font-size: 1.125rem;
  font-weight: 600;
  color: #1e293b;
  margin-bottom: 1rem;
}

.sidebar ul {
  list-style: none;
  padding: 0;
  margin: 0;
}

.sidebar li {
  margin-bottom: 0.5rem;
}

.sidebar a {
  color: #64748b;
  text-decoration: none;
  font-size: 0.9rem;
  line-height: 1.4;
  display: block;
  padding: 0.25rem 0;
  transition: color 0.2s ease;
}

.sidebar a:hover {
  color: #1672ce;
}

.date-info {
  color: #64748b;
  font-size: 0.875rem;
  margin-bottom: 2rem;
}

.back-link {
  display: inline-flex;
  align-items: center;
  color: #1672ce;
  text-decoration: none;
  font-size: 0.875rem;
  font-weight: 500;
  margin-bottom: 2rem;
  transition: color 0.2s ease;
}

.back-link:hover {
  color: #1361b3;
}

.back-link svg {
  width: 1rem;
  height: 1rem;
  margin-right: 0.5rem;
}
</style>
</head>
<body class="bg-slate-50">
<div class="relative flex size-full min-h-screen flex-col group/design-root overflow-x-hidden" style='font-family: Inter, "Noto Sans", sans-serif;'>
<div class="layout-container flex h-full grow flex-col">
<header class="header flex items-center justify-between whitespace-nowrap border-b border-solid border-slate-200 px-4 lg:px-10 py-4 bg-white sticky top-0 z-50 shadow-sm">
<a class="flex items-center gap-3 text-slate-800 hover:text-[#1672ce] transition-colors" href="../index.html">
<div class="size-7 text-[#1672ce]">
<svg fill="none" viewBox="0 0 48 48" xmlns="http://www.w3.org/2000/svg">
<path clip-rule="evenodd" d="M39.475 21.6262C40.358 21.4363 40.6863 21.5589 40.7581 21.5934C40.7876 21.655 40.8547 21.857 40.8082 22.3336C40.7408 23.0255 40.4502 24.0046 39.8572 25.2301C38.6799 27.6631 36.5085 30.6631 33.5858 33.5858C30.6631 36.5085 27.6632 38.6799 25.2301 39.8572C24.0046 40.4502 23.0255 40.7407 22.3336 40.8082C21.8571 40.8547 21.6551 40.7875 21.5934 40.7581C21.5589 40.6863 21.4363 40.358 21.6262 39.475C21.8562 38.4054 22.4689 36.9657 23.5038 35.2817C24.7575 33.2417 26.5497 30.9744 28.7621 28.762C30.9744 26.5497 33.2417 24.7574 35.2817 23.5037C36.9657 22.4689 38.4054 21.8562 39.475 21.6262ZM4.41189 29.2403L18.7597 43.5881C19.8813 44.7097 21.4027 44.9179 22.7217 44.7893C24.0585 44.659 25.5148 44.1631 26.9723 43.4579C29.9052 42.0387 33.2618 39.5667 36.4142 36.4142C39.5667 33.2618 42.0387 29.9052 43.4579 26.9723C44.1631 25.5148 44.659 24.0585 44.7893 22.7217C44.9179 21.4027 44.7097 19.8813 43.5881 18.7597L29.2403 4.41187C27.8527 3.02428 25.8765 3.02573 24.2861 3.36776C22.6081 3.72863 20.7334 4.58419 18.8396 5.74801C16.4978 7.18716 13.9881 9.18353 11.5858 11.5858C9.18354 13.988 7.18717 16.4978 5.74802 18.8396C4.58421 20.7334 3.72865 22.6081 3.36778 24.2861C3.02574 25.8765 3.02429 27.8527 4.41189 29.2403Z" fill="currentColor" fill-rule="evenodd"></path>
</svg>
</div>
<h1 class="text-slate-800 text-lg lg:text-xl font-bold leading-tight tracking-tight">David Akinboro</h1>
</a>
<nav class="flex flex-1 justify-end items-center gap-4 lg:gap-8">
<div class="nav-links flex items-center gap-6">
<a class="text-slate-700 text-sm font-medium leading-normal hover:text-[#1672ce] transition-colors" href="../projects.html">Projects</a>
<a class="text-slate-700 text-sm font-medium leading-normal hover:text-[#1672ce] transition-colors active-nav-link" href="../insights.html">Insights</a>
</div>
<!-- Mobile menu button -->
<div class="mobile-menu">
<button type="button" class="text-slate-700 hover:text-[#1672ce] transition-colors" aria-label="Menu">
<svg class="h-6 w-6" fill="none" viewBox="0 0 24 24" stroke="currentColor">
<path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M4 6h16M4 12h16M4 18h16" />
</svg>
</button>
</div>
<div class="bg-center bg-no-repeat aspect-square bg-cover rounded-full size-8 lg:size-10 border-2 border-slate-200 shadow-sm" style='background-image: url("../images/BowersCIS.JPG");'></div>
</nav>
</header>

<main class="main-container flex flex-1 px-4 lg:px-20 xl:px-40 py-6 lg:py-10">
<div class="flex max-w-7xl w-full mx-auto">
<!-- Sidebar -->
<aside class="sidebar">
<h3>Contents</h3>
<ul>
<li><a href="#what-are-reasoning-models">What Are Reasoning Language Models?</a></li>
<li><a href="#how-do-reasoning-models-think">How Do Reasoning Models Think?</a></li>
<li><a href="#chain-of-thought">Chain-of-Thought: Showing Their Work</a></li>
<li><a href="#tree-of-thought">Tree-of-Thought: Exploring Every Path</a></li>
<li><a href="#logical-inference">Logical Inference: The AI Detective</a></li>
<li><a href="#planning-and-strategizing">How Do Reasoning Models Plan and Strategize?</a></li>
<li><a href="#methodical-exploration">Methodical Exploration: Smart Search</a></li>
<li><a href="#adaptive-learning">Adaptive Learning: Reinforcement Learning</a></li>
<li><a href="#reality-check">The Reality Check: Current Limitations</a></li>
<li><a href="#hallucination-problem">The Hallucination Problem</a></li>
<li><a href="#black-box-thought">The Black Box of Thought</a></li>
<li><a href="#beyond-training-data">Beyond the Training Data</a></li>
<li><a href="#local-solutions">Getting Stuck in Local Solutions</a></li>
<li><a href="#path-forward">The Path Forward: Active Research Directions</a></li>
</ul>
</aside>

<!-- Main Content -->
<article class="content-area">
<a href="../insights.html" class="back-link">
<svg fill="none" stroke="currentColor" stroke-width="2" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg">
<path stroke-linecap="round" stroke-linejoin="round" d="M15 19l-7-7 7-7"></path>
</svg>
Back to Insights
</a>

<h1>Understanding Reasoning in Language Models</h1>

<div class="date-info">January 2025</div>

<div id="what-are-reasoning-models">
<h2>What Are Reasoning Language Models?</h2>
<p>Reasoning in language models is all about getting them to think through problems step-by-step, similar to what we do as humans. That's essentially what reasoning language models aim to achieve. Unlike traditional AI that might simply recall information or generate text based on patterns, reasoning models can perform complex reasoning tasks by breaking down problems into individual steps and working through a "chain of thought" process to come up with more accurate answers.</p>

<p>In September 2024, OpenAI released o1-preview, an LLM with enhanced reasoning capabilities, followed by o3 and o4-mini models that use reinforcement learning techniques to solve multi-step reasoning tasks. Similarly, DeepSeek launched their R1 model in January 2025, which enables simultaneous use of search and reasoning capabilities.</p>

<p>These models represent a fundamental shift from mere pattern recognition to genuine problem-solving, making them particularly powerful for tasks in mathematics, science, coding, and logical reasoning.</p>
</div>

<div id="how-do-reasoning-models-think">
<h2>How Do Reasoning Models Think?</h2>

<div id="chain-of-thought">
<h3>1. Chain-of-Thought (CoT): Showing Their Work</h3>
<p>Remember when your math teacher insisted you show your work? That's exactly what Chain-of-Thought prompting does. It facilitates problem-solving by guiding the model through a step-by-step reasoning process using a coherent series of logical steps.</p>

<p><strong>Simple Example:</strong> If asked "If John has 15 apples and gives 7 to Sarah, how many does he have left?", a CoT-enabled model would reason:</p>
<ul>
<li>"John starts with 15 apples"</li>
<li>"He gives away 7 apples"</li>
<li>"The operation needed is subtraction: 15 - 7 = 8"</li>
<li>"Therefore, John has 8 apples left"</li>
</ul>

<p>This transparency dramatically improves accuracy on tasks involving logic and common sense reasoning. By guiding the model to "think aloud," CoT improves accuracy, especially in tasks involving logic, math, and complex decision-making.</p>
</div>

<div id="tree-of-thought">
<h3>2. Tree-of-Thought (ToT): Exploring Every Path</h3>
<p>While Chain-of-Thought follows a single reasoning path, Tree of Thoughts maintains a tree of thoughts, where thoughts represent coherent language sequences that serve as intermediate steps toward solving a problem. Think of it like a chess grandmaster considering multiple moves simultaneously.</p>

<p>ToT expands the traditional "left-to-right" token generation reasoning process into a "tree structure exploration," where each node represents a thought unit. This supports multi-path attempts, backtracking, forward reasoning, and self-evaluation within the reasoning process.</p>

<p>The model can:</p>
<ul>
<li>Generate multiple solution paths</li>
<li>Evaluate the potential of each path</li>
<li>Backtrack from dead ends</li>
<li>Choose the most promising route</li>
</ul>
</div>

<div id="logical-inference">
<h3>3. Logical Inference: The AI Detective</h3>
<p>This is the classic Sherlock Holmes-style reasoning. The model draws conclusions based on given information and rules. For example:</p>
<ul>
<li>Rule: All cats are mammals</li>
<li>Fact: Fluffy is a cat</li>
<li>Conclusion: Therefore, Fluffy is a mammal</li>
</ul>

<p>However, this is also where limitations appear. If the initial rules are flawed, the AI can make incorrect logical leaps.</p>
</div>
</div>

<div id="planning-and-strategizing">
<h2>How Do Reasoning Models Plan and Strategize?</h2>

<div id="methodical-exploration">
<h3>Methodical Exploration: Smart Search</h3>
<p>When facing problems with clear goals and defined rules, reasoning models use algorithms like A* Search. The model:</p>
<ul>
<li>Builds a mental map of explored paths</li>
<li>Makes educated guesses about promising directions</li>
<li>Prioritizes the most efficient routes</li>
<li>Avoids revisiting dead ends</li>
</ul>

<p>This allows AI to find optimal solutions without exploring every possibility—much like how you'd navigate a maze by being systematic rather than random.</p>
</div>

<div id="adaptive-learning">
<h3>Adaptive Learning: Reinforcement Learning</h3>
<p>For reasoning language models, the prompt describes a reasoning task, and the reward would be high if the response solves the task, and low if the response fails to solve the task. Through millions of practice runs, the model:</p>
<ul>
<li>Tries different approaches</li>
<li>Receives rewards for good moves</li>
<li>Gets penalties for mistakes</li>
<li>Gradually develops winning strategies</li>
</ul>

<p>Most recent systems use policy-gradient methods such as Proximal Policy Optimization (PPO) because PPO constrains each policy update with a clipped objective, which stabilizes training for very large policies.</p>
</div>
</div>

<div id="reality-check">
<h2>The Reality Check: Current Limitations</h2>
<p>Despite impressive capabilities, reasoning models face major challenges that we must understand:</p>

<div id="hallucination-problem">
<h3>1. The Hallucination Problem</h3>
<p>Perhaps the most concerning limitation is that OpenAI's latest reasoning systems show hallucination rates reaching 33% for their o3 model and 48% for o4-mini when answering questions about public figures on the PersonQA benchmark. This is particularly troubling because reasoning models hallucinate more often than traditional "non-reasoning" models.</p>

<p>Reasoning requires an element of creativity, and errors that go undetected as part of that process could compound while a model works through a problem.</p>
</div>

<div id="black-box-thought">
<h3>2. The Black Box of Thought</h3>
<p>Even with Chain-of-Thought making reasoning more transparent, understanding why an AI arrived at a particular conclusion can still be challenging. As models become more complex, the "thought process" becomes a tangled web, making it difficult to:</p>
<ul>
<li>Debug errors</li>
<li>Identify biases</li>
<li>Build trust in the AI's reasoning</li>
</ul>
</div>

<div id="beyond-training-data">
<h3>3. Beyond the Training Data</h3>
<p>Current models struggle with truly novel problems that fall outside their training distribution. Hallucination is defined as inconsistencies between a computable LLM and a computable ground truth function, and it is impossible to eliminate hallucination in LLMs. True intelligence requires reasoning and learning in completely new contexts—a capability that remains elusive.</p>
</div>

<div id="local-solutions">
<h3>4. Getting Stuck in Local Solutions</h3>
<p>In planning tasks, models face the challenge of balancing exploration (trying new strategies) with exploitation (sticking to known good strategies). They can get stuck in "local optima"—good but not optimal solutions.</p>
</div>
</div>

<div id="path-forward">
<h2>The Path Forward: Active Research Directions</h2>
<p>The good news is that these limitations are driving exciting research:</p>

<ul>
<li><strong>Neuro-Symbolic AI:</strong> Combining neural networks' pattern recognition with symbolic AI's logical reasoning</li>
<li><strong>Causal Inference:</strong> Developing models that understand cause-and-effect relationships, not just correlations</li>
<li><strong>Lifelong Learning:</strong> Building systems that continuously learn without forgetting previous knowledge</li>
<li><strong>Improved Explainability:</strong> New methods to visualize and understand complex reasoning processes</li>
</ul>

<p>Recent papers like "Towards Large Reasoning Models: A Survey of Reinforced Reasoning with Large Language Models" and "Reasoning Language Models: A Blueprint" are pushing the boundaries of what's possible.</p>

<p>These foundational concepts will help you understand the technical details and implications of my research findings as we explore them together.</p>
</div>

</article>
</div>
</main>

<footer class="bg-slate-800 text-slate-300">
<div class="flex justify-center">
<div class="flex max-w-[960px] flex-1 flex-col">
<div class="flex flex-col gap-6 px-5 py-10 text-center @container items-center">
<div class="flex flex-wrap justify-center gap-5">
<a class="text-slate-400 hover:text-white transition-colors" href="https://www.linkedin.com/in/davidakinboro/" target="_blank" aria-label="LinkedIn Profile">
<svg fill="currentColor" height="28px" viewBox="0 0 256 256" width="28px" xmlns="http://www.w3.org/2000/svg">
<path d="M216,24H40A16,16,0,0,0,24,40V216a16,16,0,0,0,16,16H216a16,16,0,0,0,16-16V40A16,16,0,0,0,216,24Zm0,192H40V40H216V216ZM96,112v64a8,8,0,0,1-16,0V112a8,8,0,0,1,16,0Zm88,28v36a8,8,0,0,1-16,0V140a20,20,0,0,0-40,0v36a8,8,0,0,1-16,0V112a8,8,0,0,1,15.79-1.78A36,36,0,0,1,184,140ZM100,84A12,12,0,1,1,88,72,12,12,0,0,1,100,84Z"></path>
</svg>
</a>
<a class="text-slate-400 hover:text-white transition-colors" href="https://github.com/UPSD1" target="_blank" aria-label="GitHub Profile">
<svg fill="currentColor" height="28px" viewBox="0 0 256 256" width="28px" xmlns="http://www.w3.org/2000/svg">
<path d="M208.31,75.68A59.78,59.78,0,0,0,202.93,28,8,8,0,0,0,196,24a59.75,59.75,0,0,0-48,24H124A59.75,59.75,0,0,0,76,24a8,8,0,0,0-6.93,4,59.78,59.78,0,0,0-5.38,47.68A58.14,58.14,0,0,0,56,104v8a56.06,56.06,0,0,0,48.44,55.47A39.8,39.8,0,0,0,96,192v8H72a24,24,0,0,1-24-24A40,40,0,0,0,8,136a8,8,0,0,0,0,16,24,24,0,0,1,24,24,40,40,0,0,0,40,40H96v16a8,8,0,0,0,16,0V192a24,24,0,0,1,48,0v40a8,8,0,0,0,16,0V192a39.8,39.8,0,0,0-8.44-24.53A56.06,56.06,0,0,0,216,112v-8A58.14,58.14,0,0,0,208.31,75.68ZM200,112a40,40,0,0,1-40,40H112a40,40,0,0,1-40-40v-8a41.74,41.74,0,0,1,6.9-22.48A8,8,0,0,0,80,73.83a43.81,43.81,0,0,1,.79-33.58,43.88,43.88,0,0,1,32.32,20.06A8,8,0,0,0,119.82,64h32.35a8,8,0,0,0,6.74-3.69,43.87,43.87,0,0,1,32.32-20.06A43.81,43.81,0,0,1,192,73.83a8.09,8.09,0,0,0,1,7.65A41.72,41.72,0,0,1,200,104Z"></path>
</svg>
</a>
</div>
<p class="text-slate-400 text-sm font-normal leading-normal">© 2025 David Akinboro. All rights reserved.</p>
</div>
</div>
</div>
</footer>
</div>
</div>

<script>
// Smooth scrolling for anchor links
document.querySelectorAll('a[href^="#"]').forEach(anchor => {
  anchor.addEventListener('click', function (e) {
    e.preventDefault();
    const targetId = this.getAttribute('href');
    const targetElement = document.querySelector(targetId);
    if (targetElement) {
      targetElement.scrollIntoView({
        behavior: 'smooth',
        block: 'start' 
      });
    }
  });
});

// Highlight current section in sidebar
function highlightCurrentSection() {
  const sections = document.querySelectorAll('[id]');
  const sidebarLinks = document.querySelectorAll('.sidebar a');
  
  let currentSection = '';
  
  sections.forEach(section => {
    const rect = section.getBoundingClientRect();
    if (rect.top <= 150 && rect.bottom >= 150) {
      currentSection = section.id;
    }
  });
  
  sidebarLinks.forEach(link => {
    link.style.color = '#64748b';
    if (link.getAttribute('href') === `#${currentSection}`) {
      link.style.color = '#1672ce';
    }
  });
}

window.addEventListener('scroll', highlightCurrentSection);
window.addEventListener('load', highlightCurrentSection);
</script>

</body></html>